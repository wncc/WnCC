<hr />
<p>This project will focus on getting human pose estimates in games to generate a dataset using no manual annotations or labelling.</p>

<!--break-->

<p>Deep networks are very data hungry in this age. Annotating lots of data is very tedious, expensive, and inefficient.</p>

<!--break-->

<p>However, a lot of ground truth data can be easily generated by using the rendering of video games to extract specific information like semantic segmentation, depth maps, etc. The project will focus on getting human pose estimates in games to generate a “in-the-wild” dataset using no manual annotations or labelling.</p>

<!--break-->

<p>This will be done by injecting specialized code into the DirectX rendering API. We’ll further test the effectiveness of the dataset on real images to see if such a dataset can provide benefits in training.</p>

<!--break-->
<h2 id="timeline">Timeline</h2>

<table>
  <thead>
    <tr>
      <th>Week</th>
      <th>Task</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Week1</td>
      <td>Understand the main paper, and what pose estimation is</td>
    </tr>
    <tr>
      <td>Week2</td>
      <td>Download a free game and start exploring the DirectX API</td>
    </tr>
    <tr>
      <td>Week 3, 4</td>
      <td>Extract the pose information from pre-renders</td>
    </tr>
    <tr>
      <td>Week 5, 6</td>
      <td>Cleaning up the dataset, and testing a small DNN to predict pose</td>
    </tr>
    <tr>
      <td>Week 7, 8</td>
      <td>Try on one more game and start testing on real datasets</td>
    </tr>
  </tbody>
</table>
